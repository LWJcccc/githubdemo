{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:37.808918Z",
     "start_time": "2020-11-30T03:06:37.798937Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据预处理\n",
    "data_path: 数据集路径\n",
    "return: train, test:处理后的训练集数据、测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:42.087484Z",
     "start_time": "2020-11-30T03:06:42.069531Z"
    }
   },
   "outputs": [],
   "source": [
    "def processing_data(data_path):\n",
    "    # 生成训练集\n",
    "    train_data = ImageDataGenerator(\n",
    "            # 浮点数，图片宽度的某个比例，数据提升时图片水平偏移的幅度\n",
    "            width_shift_range=0.1,\n",
    "            # 浮点数，图片高度的某个比例，数据提升时图片竖直偏移的幅度\n",
    "            height_shift_range=0.1,\n",
    "            # 浮点数，剪切强度（逆时针方向的剪切变换角度）\n",
    "            shear_range=0.1,  \n",
    "            # 随机缩放的幅度，若为浮点数，则相当于[lower,upper] = [1 - zoom_range, 1+zoom_range]\n",
    "            zoom_range=0.1,\n",
    "            # 布尔值，进行随机水平翻转\n",
    "            horizontal_flip=True,\n",
    "            # 对图片的每个像素值均乘上这个放缩因子，把像素值放缩到0和1之间有利于模型的收敛\n",
    "            vertical_flip=True,\n",
    "            # 在 0 和 1 之间浮动。用作验证集的训练数据的比例\n",
    "            rescale=1. / 225\n",
    "            )\n",
    " \n",
    "    # 生成测试集\n",
    "    validation_data = ImageDataGenerator(\n",
    "            rescale=1./ 255,\n",
    "            )\n",
    " \n",
    "    # 以文件夹路径为参数,生成经过归一化后的数据,在一个无限循环中无限产生batch数据\n",
    "    train_generator = train_data.flow_from_directory(\n",
    "            # 提供的路径下面需要有子目录\n",
    "            data_path, \n",
    "            # 整数元组 (height, width)，默认：(256, 256)。 所有的图像将被调整到的尺寸。\n",
    "            target_size=(150, 150),\n",
    "            # 一批数据的大小\n",
    "            batch_size=256,\n",
    "            # \"categorical\", \"binary\", \"sparse\", \"input\" 或 None 之一。\n",
    "            # 默认：\"categorical\",返回one-hot 编码标签。\n",
    "            class_mode='categorical',\n",
    "            )\n",
    "    validation_generator = validation_data.flow_from_directory(\n",
    "            data_path,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=256,\n",
    "            class_mode='categorical',\n",
    "            )\n",
    " \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-30T03:07:46.647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10412 images belonging to 4 classes.\n",
      "Found 10412 images belonging to 4 classes.\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def model(train_generator, validation_generator, save_model_path, epochs):\n",
    "    start = time.time()\n",
    " \n",
    "    '''\n",
    "    使用keras的已封装的vgg16建立一个模型，构建的模型会将VGG16顶层（全连接层）\n",
    "去掉只保留其余的网络结构（去掉全连接层，前面都是卷积层）\n",
    "    weights='imagenet' 使用ImageNet上预训练的模型，用ImageNet的参数初始化模型的参数\n",
    "    include_top = False 是否包含最上层的全连接层 表明迁移除顶层以外的其余网络结构到自己的模型中\n",
    "    input_shape 输入进来的数据是150*150 3通道\n",
    "    通过.add()方法一个个的将layer加入模型中\n",
    "    '''\n",
    "    vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "    top_model = Sequential()\n",
    "    # Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡\n",
    "    top_model.add(Flatten(input_shape=vgg16_model.output_shape[1:]))\n",
    "    # dense 全连接 activation: 激活函数\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(4, activation='softmax'))\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(vgg16_model)\n",
    "    model.add(top_model)\n",
    " \n",
    "    # 配置模型学习过程\n",
    "    model.compile(\n",
    "             # 优化器, 主要有Adam、sgd、rmsprop等方式\n",
    "            # SGD 每次更新时对每个样本进行梯度更新, 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本\n",
    "            # lr: float >= 0. 学习率, momentum: float >= 0. 参数，用于加速 SGD 在相关方向上前进，并抑制震荡\n",
    "            optimizer=SGD(lr=1e-3, momentum=0.9),\n",
    "            # 损失函数,多分类采用 categorical_crossentropy（亦称作多类的对数损失）\n",
    "            loss='categorical_crossentropy',\n",
    "            # 评价函数 训练和测试期间的模型评估标准 除了损失函数值之外的特定指标, 分类问题一般都是准确率\n",
    "            metrics=['accuracy'])\n",
    " \n",
    "    # 训练\n",
    "    # 返回一个history 记录了训练过程 fit_generator分批次读取 逐个生成数据的batch并进行训练\n",
    "    model.fit_generator(\n",
    "            # generator:生成器函数 一个生成器或 Sequence 对象的实例\n",
    "            generator=train_generator,\n",
    "            # epochs: 整数，数据的迭代总轮数。\n",
    "            epochs=epochs,\n",
    "            # 每轮步数 一个epoch包含的步数,通常应该等于你的数据集的样本数量除以批量大小。\n",
    "            steps_per_epoch=10412 //256,\n",
    "            # 验证集\n",
    "            validation_data=validation_generator,\n",
    "             # 在验证集上,一个epoch包含的步数,通常应该等于你的数据集的样本数量除以批量大小。\n",
    "            validation_steps=4608// 256,\n",
    "            )\n",
    "    model.save(save_model_path)\n",
    "    end = time.time()\n",
    "    print(\"训练完毕,模型已保存！总耗时：%d 秒\" % (end - start)) \n",
    "    return model\n",
    " \n",
    "epochs =3\n",
    "# 数据集路径\n",
    "data_path ='train/'\n",
    "# 保存模型路径和名称\n",
    "save_model_path = 'results/model_20.h5'\n",
    "# 获取数据\n",
    "train_generator, validation_generator = processing_data(data_path)\n",
    "# 创建、训练和保存模型\n",
    "model(train_generator, validation_generator, save_model_path, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T08:05:58.221Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from keras.models import load_model\n",
    "from model_cret import processing_data\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# 评估模型\n",
    "def evaluate_mode(validation_generator):\n",
    "    # 加载模型\n",
    "    model = load_model('results/model_20.h5')\n",
    " \n",
    "    history = model.fit_generator(\n",
    "        # 一个生成器或 Sequence 对象的实例\n",
    "        generator=train_generator,\n",
    "        # epochs: 整数，数据的迭代总轮数。\n",
    "        epochs=20,\n",
    "        # 一个epoch包含的步数,通常应该等于你的数据集的样本数量除以批量大小。\n",
    "        steps_per_epoch=2259 // 16,\n",
    "        # 验证集\n",
    "        validation_data=validation_generator,\n",
    "        # 在验证集上,一个epoch包含的步数,通常应该等于你的数据集的样本数量除以批量大小。\n",
    "        validation_steps=248 // 16,\n",
    "    )\n",
    " \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('model_accuracy.png')\n",
    " \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('model_loss.png')\n",
    "    plt.show()\n",
    " \n",
    "    # 获取验证集的 loss 和 accuracy\n",
    "    loss, accuracy = model.evaluate_generator(validation_generator)\n",
    "    print(\"模型评估：\")\n",
    "    print(\"Loss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy * 100))\n",
    " \n",
    "    print(model.summary())\n",
    " \n",
    "# 数据集路径\n",
    "data_path = 'dataset/'\n",
    "train_generator, validation_generator = processing_data(data_path)\n",
    "evaluate_mode(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T06:36:06.655Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "\"\"\"\n",
    "    加载模型和模型预测\n",
    "    主要步骤:\n",
    "        1.加载模型\n",
    "        2.图片处理\n",
    "        3.用加载的模型预测图片的类别\n",
    "    :param img: PIL.Image 对象\n",
    "    :return: string, 模型识别图片的类别, \n",
    "            共 'cardboard','glass','metal','paper','plastic','trash' 6 个类别\n",
    "\"\"\"\n",
    "def predict(img_path):\n",
    "    # 把图片转换成为numpy数组\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img = image.img_to_array(img)\n",
    " \n",
    "    # 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "    # 如果你的模型是在 results 文件夹下的 dnn.h5 模型，则 model_path = 'results/dnn.h5'\n",
    "    model_path = 'results/model_20.h5'\n",
    "    # 加载模型\n",
    "    model = load_model(model_path)\n",
    " \n",
    "    # expand_dims的作用是把img.shape转换成(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    # 给函数增加维度\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    # 模型预测\n",
    "    y = model.predict(x)\n",
    " \n",
    "    # 获取labels\n",
    "    labels = {0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n",
    "    predict = labels[np.argmax(y)]\n",
    " \n",
    "    # 返回图片的类别\n",
    "    return predict\n",
    " \n",
    "img_path = 'testImg/cardboard2.jpg'\n",
    "frame = cv2.imread(img_path)\n",
    "# 定义字体\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(frame, predict(img_path), (10, 140), font, 3, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "cv2.imwrite('results/pred.png', frame)\n",
    "cv2.imshow('img', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    " \n",
    "# 创建窗口 设定大小并命名\n",
    "window = tk.Tk()\n",
    "window.title('垃圾分类')\n",
    "window.geometry('1050x500')\n",
    "global img_png           # 定义全局变量 图像的\n",
    "var = tk.StringVar()    # 这时文字变量储存器\n",
    " \n",
    "mainframe = ttk.Frame(window, padding=\"5 4 12 12\")\n",
    "mainframe.grid(column=0, row=0, sticky=(N, W, E, S))\n",
    "mainframe.columnconfigure(0, weight=1)\n",
    "mainframe.rowconfigure(0, weight=1)\n",
    " \n",
    "def openImg():\n",
    "    global img_png\n",
    "    var.set('已打开')\n",
    "    Img = Image.open('testImg/cardboard2.jpg')\n",
    "    img_png = ImageTk.PhotoImage(Img)\n",
    "    label_Img2 = tk.Label(image=img_png).grid(column=2, row=2, sticky=W)\n",
    " \n",
    "num = 1\n",
    "def change():       #更新图片操作\n",
    "    global num\n",
    "    var.set('已预测')\n",
    "    num=num+1\n",
    "    if num%3==0:\n",
    "        url1=\"results/pred.png\"\n",
    "        pil_image = Image.open(url1)\n",
    "        img= ImageTk.PhotoImage(pil_image)\n",
    "        label_img.configure(image = img)\n",
    "    window.update_idletasks()   #更新图片，必须update\n",
    " \n",
    "# row = 1\n",
    "# epochs = StringVar()\n",
    "# ttk.Label(mainframe, text=\"epochs:\").grid(column=1, row=1, sticky=W)\n",
    "# addr_entry = ttk.Entry(mainframe, width=7, textvariable=epochs)\n",
    "# addr_entry.grid(column=2, row=1, sticky=(W, E))\n",
    "#\n",
    "# ttk.Button(mainframe, text=\"Train\").grid(column=4, row=1, sticky=W)\n",
    " \n",
    "# row = 2\n",
    "ttk.Button(mainframe, text=\"打开\", command=openImg).grid(column=1, row=2, sticky=W)\n",
    "ttk.Button(mainframe, text=\"预测\", command=change).grid(column=3, row=2, sticky=W)\n",
    " \n",
    "# row = 3 创建文本窗口，显示当前操作状态\n",
    "ttk.Label(mainframe, text=\"状态\").grid(column=1, row=3, sticky=W)\n",
    "ttk.Label(mainframe, textvariable=var).grid(column=3, row=3, sticky=W)\n",
    " \n",
    "url = \"testImg/logo.jpg\"\n",
    "pil_image = Image.open(url)\n",
    "img= ImageTk.PhotoImage(pil_image)\n",
    "label_img = ttk.Label(window, image = img ,compound=CENTER)\n",
    "label_img.grid(column=0, row=2, sticky=W)\n",
    " \n",
    "# 运行整体窗口\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
